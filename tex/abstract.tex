\begin{abstract}

As the computing industry embraces increasingly large and heterogenous
systems, a key research challenge is the question of how to integrate
hardware accelerators without adversely impacting the conventional
virtual memory (VM) abstractions modern complex software stacks rely
on. Unfortunately, VM support for accelerators is fundamentally
different from CPUs due to prohibitive TLB reach requirements, tight
area and power budgets, and increasing latency of page table
walks. Moreover, recent proposals for accelerator VM break
conventional VM abstractions with intrusive OS changes to facilitate
address translation.


We propose DTRIM, a set-associative VM architecture for large
heterogeneous systems.  We show that maintaining the portion of the
address space accelerators operate on set-associatively has virtually
no impact on page fault traffic, but significantly reduces translation
hardware requirements and page-walk latency.  A tiny reduction in the
associativity of virtual-to-physical address mapping allows DTRIM to
partition the memory space and delegate the address translation to the
memory partition that holds the data, where memory-side per-partition
TLBs and MMUs can locally translate addresses at lower latency and
with higher efficiency. In doing so, DTRIM significantly improves TLB
hit rates and breaks page walk-data fetch serialization upon TLB
misses. DTRIM virtually eliminates the translation overhead 
by reducing it by over 30x on average (up to 47x). Finally, we implement DTRIM
in stock Linux, showing that these benefits are achievable while
retaining conventional VM abstractions and with only modest changes to
existing VM software stacks.

\end{abstract}

