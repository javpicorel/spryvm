\begin{abstract}


With the slowdown in  silicon efficiency and density scaling, near-memory accelerators are emerging as a promising solution to bridging the logic/memory gap in online analytic workloads and services. The key challenge in incorporating accelerators into a modern platform, however, is doing so without impacting the conventional virtual memory abstractions modern complex software stacks rely on. Unfortunately, VM support for accelerators is fundamentally different from CPU's due to prohibitive TLB reach requirements, long-latency page table walks and tight budgets for silicon resources and footprints. Moreover, recent proposals for accelerator VM support break the conventional VM abstractions with intrusive solutions to software stack to facilitate address translation.

In this paper, we propose spryVM, a set-associate VM for in-memory workloads. We show that maintaining the portion of the address space accelerators operate on set-associatively in practice has little impact on page fault traffic but dramatically reduces both the VM hardware support requirements and preserves demand paging to minimize the impact on existing software stacks. We observe that address translation overheads arise not just because TLBs miss frequently, but also because page table walks must complete {\it before} data access can proceed. SpryVM mitigates this translation-data access serialization by dividing memory into set-associative accelerator-local partitions which can mapped and walked locally. By overlapping page walks and data fetch operations almost entirely, SpryVM achieves within 1.2\% and 0.6\% of ideal translation in scenarios where working sets are memory-resident and exceed the available memory capacity, respectively. 



\end{abstract}

